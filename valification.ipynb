{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Target Encoder\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "import category_encoders.utils as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'chappers'\n",
    "class TargetEncoder(util.BaseEncoder, util.SupervisedTransformerMixin):\n",
    "    \"\"\"Target encoding for categorical features.\n",
    "\n",
    "    Supported targets: binomial and continuous. For polynomial target support, see PolynomialWrapper.\n",
    "\n",
    "    For the case of categorical target: features are replaced with a blend of posterior probability of the target\n",
    "    given particular categorical value and the prior probability of the target over all the training data.\n",
    "\n",
    "    For the case of continuous target: features are replaced with a blend of the expected value of the target\n",
    "    given particular categorical value and the expected value of the target over all the training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    verbose: int\n",
    "        integer indicating verbosity of the output. 0 for none.\n",
    "    cols: list\n",
    "        a list of columns to encode, if None, all string columns will be encoded.\n",
    "    drop_invariant: bool\n",
    "        boolean for whether or not to drop columns with 0 variance.\n",
    "    return_df: bool\n",
    "        boolean for whether to return a pandas DataFrame from transform (otherwise it will be a numpy array).\n",
    "    handle_missing: str\n",
    "        options are 'error', 'return_nan'  and 'value', defaults to 'value', which returns the target mean.\n",
    "    handle_unknown: str\n",
    "        options are 'error', 'return_nan' and 'value', defaults to 'value', which returns the target mean.\n",
    "    min_samples_leaf: int\n",
    "        For regularization the weighted average between category mean and global mean is taken. The weight is\n",
    "        an S-shaped curve between 0 and 1 with the number of samples for a category on the x-axis.\n",
    "        The curve reaches 0.5 at min_samples_leaf. (parameter k in the original paper)\n",
    "    smoothing: float\n",
    "        smoothing effect to balance categorical average vs prior. Higher value means stronger regularization.\n",
    "        The value must be strictly bigger than 0. Higher values mean a flatter S-curve (see min_samples_leaf).\n",
    "    hierarchy: dict or dataframe\n",
    "        A dictionary or a dataframe to define the hierarchy for mapping.\n",
    "\n",
    "        If a dictionary, this contains a dict of columns to map into hierarchies.  Dictionary key(s) should be the column name from X\n",
    "        which requires mapping.  For multiple hierarchical maps, this should be a dictionary of dictionaries.\n",
    "\n",
    "        If dataframe: a dataframe defining columns to be used for the hierarchies.  Column names must take the form:\n",
    "            HIER_colA_1, ... HIER_colA_N, HIER_colB_1, ... HIER_colB_M, ...\n",
    "        where [colA, colB, ...] are given columns in cols list.  \n",
    "        1:N and 1:M define the hierarchy for each column where 1 is the highest hierarchy (top of the tree).  A single column or multiple \n",
    "        can be used, as relevant.\n",
    "\n",
    "    Examples\n",
    "    -------\n",
    "    >>> from category_encoders import *\n",
    "    >>> import pandas as pd\n",
    "    >>> from sklearn.datasets import fetch_openml\n",
    "    >>> display_cols = [\"Id\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"YearBuilt\", \"Heating\", \"CentralAir\"]\n",
    "    >>> bunch = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "    >>> y = bunch.target > 200000\n",
    "    >>> X = pd.DataFrame(bunch.data, columns=bunch.feature_names)[display_cols]\n",
    "    >>> enc = TargetEncoder(cols=['CentralAir', 'Heating'], min_samples_leaf=20, smoothing=10).fit(X, y)\n",
    "    >>> numeric_dataset = enc.transform(X)\n",
    "    >>> print(numeric_dataset.info())\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    RangeIndex: 1460 entries, 0 to 1459\n",
    "    Data columns (total 7 columns):\n",
    "     #   Column       Non-Null Count  Dtype  \n",
    "    ---  ------       --------------  -----  \n",
    "     0   Id           1460 non-null   float64\n",
    "     1   MSSubClass   1460 non-null   float64\n",
    "     2   MSZoning     1460 non-null   object \n",
    "     3   LotFrontage  1201 non-null   float64\n",
    "     4   YearBuilt    1460 non-null   float64\n",
    "     5   Heating      1460 non-null   float64\n",
    "     6   CentralAir   1460 non-null   float64\n",
    "    dtypes: float64(6), object(1)\n",
    "    memory usage: 80.0+ KB\n",
    "    None\n",
    "   \n",
    "    >>> from category_encoders.datasets import load_compass\n",
    "    >>> X, y = load_compass()\n",
    "    >>> hierarchical_map = {'compass': {'N': ('N', 'NE'), 'S': ('S', 'SE'), 'W': 'W'}}\n",
    "    >>> enc = TargetEncoder(verbose=1, smoothing=2, min_samples_leaf=2, hierarchy=hierarchical_map, cols=['compass']).fit(X.loc[:,['compass']], y)\n",
    "    >>> hierarchy_dataset = enc.transform(X.loc[:,['compass']])\n",
    "    >>> print(hierarchy_dataset['compass'].values)\n",
    "    [0.62263617 0.62263617 0.90382995 0.90382995 0.90382995 0.17660024\n",
    "     0.17660024 0.46051953 0.46051953 0.46051953 0.46051953 0.40332791\n",
    "     0.40332791 0.40332791 0.40332791 0.40332791]\n",
    "    >>> X, y = load_postcodes('binary')\n",
    "    >>> cols = ['postcode']\n",
    "    >>> HIER_cols = ['HIER_postcode_1','HIER_postcode_2','HIER_postcode_3','HIER_postcode_4']\n",
    "    >>> enc = TargetEncoder(verbose=1, smoothing=2, min_samples_leaf=2, hierarchy=X[HIER_cols], cols=['postcode']).fit(X['postcode'], y)\n",
    "    >>> hierarchy_dataset = enc.transform(X['postcode'])\n",
    "    >>> print(hierarchy_dataset.loc[0:10, 'postcode'].values)\n",
    "    [0.75063473 0.90208756 0.88328833 0.77041254 0.68891504 0.85012847\n",
    "    0.76772574 0.88742357 0.7933824  0.63776756 0.9019973 ]\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "\n",
    "    .. [1] A Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction Problems, from\n",
    "    https://dl.acm.org/citation.cfm?id=507538\n",
    "\n",
    "    \"\"\"\n",
    "    prefit_ordinal = True\n",
    "    encoding_relation = util.EncodingRelation.ONE_TO_ONE\n",
    "\n",
    "    def __init__(self, verbose=0, cols=None, drop_invariant=False, return_df=True, handle_missing='value',\n",
    "                 handle_unknown='value', min_samples_leaf=20, smoothing=10, hierarchy=None):\n",
    "        super().__init__(verbose=verbose, cols=cols, drop_invariant=drop_invariant, return_df=return_df,\n",
    "                         handle_unknown=handle_unknown, handle_missing=handle_missing)\n",
    "        self.ordinal_encoder = None\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.smoothing = smoothing\n",
    "        self.mapping = None\n",
    "        self._mean = None\n",
    "        if isinstance(hierarchy, (dict, pd.DataFrame)) and cols is None:\n",
    "            raise ValueError('Hierarchy is defined but no columns are named for encoding')\n",
    "        if isinstance(hierarchy, dict):\n",
    "            self.hierarchy = {}\n",
    "            self.hierarchy_depth = {}\n",
    "            for switch in hierarchy:\n",
    "                flattened_hierarchy = util.flatten_reverse_dict(hierarchy[switch])\n",
    "                hierarchy_check = self._check_dict_key_tuples(flattened_hierarchy)\n",
    "                self.hierarchy_depth[switch] = hierarchy_check[1]\n",
    "                if not hierarchy_check[0]:\n",
    "                    raise ValueError('Hierarchy mapping contains different levels for key \"' + switch + '\"')\n",
    "                self.hierarchy[switch] = {(k if isinstance(t, tuple) else t): v for t, v in flattened_hierarchy.items() for k in t}\n",
    "        elif isinstance(hierarchy, pd.DataFrame):\n",
    "            self.hierarchy = hierarchy\n",
    "            self.hierarchy_depth = {}\n",
    "            for col in self.cols:\n",
    "                HIER_cols = self.hierarchy.columns[self.hierarchy.columns.str.startswith(f'HIER_{col}')].tolist()\n",
    "                HIER_levels = [int(i.replace(f'HIER_{col}_', '')) for i in HIER_cols]\n",
    "                if np.array_equal(sorted(HIER_levels), np.arange(1, max(HIER_levels)+1)):\n",
    "                    self.hierarchy_depth[col] = max(HIER_levels)\n",
    "                else:\n",
    "                    raise ValueError(f'Hierarchy columns are not complete for column {col}')\n",
    "        elif hierarchy is None:\n",
    "            self.hierarchy = hierarchy\n",
    "        else:\n",
    "            raise ValueError('Given hierarchy mapping is neither a dictionary nor a dataframe')\n",
    "\n",
    "        self.cols_hier = []\n",
    "\n",
    "    def _check_dict_key_tuples(self, d):\n",
    "        min_tuple_size = min(len(v) for v in d.values())\n",
    "        max_tuple_size = max(len(v) for v in d.values())\n",
    "        return min_tuple_size == max_tuple_size, min_tuple_size\n",
    "\n",
    "    def _fit(self, X, y, **kwargs):\n",
    "        if isinstance(self.hierarchy, dict):\n",
    "            X_hier = pd.DataFrame()\n",
    "            for switch in self.hierarchy:\n",
    "                if switch in self.cols:\n",
    "                    colnames = [f'HIER_{str(switch)}_{str(i + 1)}' for i in range(self.hierarchy_depth[switch])]\n",
    "                    df = pd.DataFrame(X[str(switch)].map(self.hierarchy[str(switch)]).tolist(), index=X.index, columns=colnames)\n",
    "                    X_hier = pd.concat([X_hier, df], axis=1)\n",
    "        elif isinstance(self.hierarchy, pd.DataFrame):\n",
    "            X_hier = self.hierarchy\n",
    "\n",
    "        if isinstance(self.hierarchy, (dict, pd.DataFrame)):\n",
    "            enc_hier = OrdinalEncoder(\n",
    "                verbose=self.verbose,\n",
    "                cols=X_hier.columns,\n",
    "                handle_unknown='value',\n",
    "                handle_missing='value'\n",
    "            )\n",
    "            enc_hier = enc_hier.fit(X_hier)\n",
    "            X_hier_ordinal = enc_hier.transform(X_hier)\n",
    "\n",
    "        self.ordinal_encoder = OrdinalEncoder(\n",
    "            verbose=self.verbose,\n",
    "            cols=self.cols,\n",
    "            handle_unknown='value',\n",
    "            handle_missing='value'\n",
    "        )\n",
    "        self.ordinal_encoder = self.ordinal_encoder.fit(X)\n",
    "        X_ordinal = self.ordinal_encoder.transform(X)\n",
    "        if self.hierarchy is not None:\n",
    "            self.mapping = self.fit_target_encoding(pd.concat([X_ordinal, X_hier_ordinal], axis=1), y)\n",
    "        else:\n",
    "            self.mapping = self.fit_target_encoding(X_ordinal, y)\n",
    "\n",
    "    def fit_target_encoding(self, X, y):\n",
    "        mapping = {}\n",
    "        prior = self._mean = y.mean()\n",
    "\n",
    "        for switch in self.ordinal_encoder.category_mapping:\n",
    "            col = switch.get('col')\n",
    "            if 'HIER_' not in str(col):\n",
    "                values = switch.get('mapping')\n",
    "\n",
    "                scalar = prior\n",
    "                if (isinstance(self.hierarchy, dict) and col in self.hierarchy) or \\\n",
    "                                    (isinstance(self.hierarchy, pd.DataFrame)):\n",
    "                    for i in range(self.hierarchy_depth[col]):\n",
    "                        col_hier = 'HIER_'+str(col)+'_'+str(i+1)\n",
    "                        col_hier_m1 = col if i == self.hierarchy_depth[col]-1 else 'HIER_'+str(col)+'_'+str(i+2)\n",
    "                        if not X[col].equals(X[col_hier]) and len(X[col_hier].unique())>1:\n",
    "                            stats_hier = y.groupby(X[col_hier]).agg(['count', 'mean'])\n",
    "                            smoove_hier = self._weighting(stats_hier['count'])\n",
    "                            scalar_hier = scalar * (1 - smoove_hier) + stats_hier['mean'] * smoove_hier\n",
    "                            scalar_hier_long = X[[col_hier_m1, col_hier]].drop_duplicates()\n",
    "                            scalar_hier_long.index = np.arange(1, scalar_hier_long.shape[0]+1)\n",
    "                            scalar = scalar_hier_long[col_hier].map(scalar_hier.to_dict())\n",
    "\n",
    "                stats = y.groupby(X[col]).agg(['count', 'mean'])\n",
    "                smoove = self._weighting(stats['count'])\n",
    "\n",
    "                smoothing = scalar * (1 - smoove) + stats['mean'] * smoove\n",
    "\n",
    "                if self.handle_unknown == 'return_nan':\n",
    "                    smoothing.loc[-1] = np.nan\n",
    "                elif self.handle_unknown == 'value':\n",
    "                    smoothing.loc[-1] = prior\n",
    "\n",
    "                if self.handle_missing == 'return_nan':\n",
    "                    smoothing.loc[values.loc[np.nan]] = np.nan\n",
    "                elif self.handle_missing == 'value':\n",
    "                    smoothing.loc[-2] = prior\n",
    "\n",
    "                mapping[col] = smoothing\n",
    "\n",
    "        return mapping\n",
    "\n",
    "    def _transform(self, X, y=None):\n",
    "        # Now X is the correct dimensions it works with pre fitted ordinal encoder\n",
    "        X = self.ordinal_encoder.transform(X)\n",
    "\n",
    "        if self.handle_unknown == 'error':\n",
    "            if X[self.cols].isin([-1]).any().any():\n",
    "                raise ValueError('Unexpected categories found in dataframe')\n",
    "\n",
    "        X = self.target_encode(X)\n",
    "        return X\n",
    "\n",
    "    def target_encode(self, X_in):\n",
    "        X = X_in.copy(deep=True)\n",
    "\n",
    "        # Was not mapping extra columns as self.featuer_names_in did not include new column\n",
    "        for col in self.cols:\n",
    "            X[col] = X[col].map(self.mapping[col])\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _weighting(self, n):\n",
    "        # monotonically increasing function of n bounded between 0 and 1\n",
    "        # sigmoid in this case, using scipy.expit for numerical stability\n",
    "        return expit((n - self.min_samples_leaf) / self.smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Heating</th>\n",
       "      <th>CentralAir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1915</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1978</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1941</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  YearBuilt Heating CentralAir\n",
       "0        1          60       RL         65.0       2003    GasA          Y\n",
       "1        2          20       RL         80.0       1976    GasA          Y\n",
       "2        3          60       RL         68.0       2001    GasA          Y\n",
       "3        4          70       RL         60.0       1915    GasA          Y\n",
       "4        5          60       RL         84.0       2000    GasA          Y\n",
       "...    ...         ...      ...          ...        ...     ...        ...\n",
       "1455  1456          60       RL         62.0       1999    GasA          Y\n",
       "1456  1457          20       RL         85.0       1978    GasA          Y\n",
       "1457  1458          70       RL         66.0       1941    GasA          Y\n",
       "1458  1459          20       RL         68.0       1950    GasA          Y\n",
       "1459  1460          20       RL         75.0       1965    GasA          Y\n",
       "\n",
       "[1460 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from category_encoders import *\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "display_cols = [\"Id\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"YearBuilt\", \"Heating\", \"CentralAir\"]\n",
    "bunch = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "y = bunch.target > 200000\n",
    "X = pd.DataFrame(bunch.data, columns=bunch.feature_names)[display_cols]\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Heating</th>\n",
       "      <th>CentralAir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1915</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1978</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1941</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.294818</td>\n",
       "      <td>0.30989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  YearBuilt   Heating  CentralAir\n",
       "0        1          60       RL         65.0       2003  0.294818     0.30989\n",
       "1        2          20       RL         80.0       1976  0.294818     0.30989\n",
       "2        3          60       RL         68.0       2001  0.294818     0.30989\n",
       "3        4          70       RL         60.0       1915  0.294818     0.30989\n",
       "4        5          60       RL         84.0       2000  0.294818     0.30989\n",
       "...    ...         ...      ...          ...        ...       ...         ...\n",
       "1455  1456          60       RL         62.0       1999  0.294818     0.30989\n",
       "1456  1457          20       RL         85.0       1978  0.294818     0.30989\n",
       "1457  1458          70       RL         66.0       1941  0.294818     0.30989\n",
       "1458  1459          20       RL         68.0       1950  0.294818     0.30989\n",
       "1459  1460          20       RL         75.0       1965  0.294818     0.30989\n",
       "\n",
       "[1460 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc = TargetEncoder(cols=['CentralAir', 'Heating']).fit(X, y)\n",
    "numeric_dataset = enc.transform(X)\n",
    "display(numeric_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>compass</th>\n",
       "      <th>HIER_compass_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NE</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NE</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NE</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SE</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>SE</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index compass HIER_compass_1\n",
       "0       1       N              N\n",
       "1       2       N              N\n",
       "2       3      NE              N\n",
       "3       4      NE              N\n",
       "4       5      NE              N\n",
       "5       6      SE              S\n",
       "6       7      SE              S\n",
       "7       8       S              S\n",
       "8       9       S              S\n",
       "9      10       S              S\n",
       "10     11       S              S\n",
       "11     12       W              W\n",
       "12     13       W              W\n",
       "13     14       W              W\n",
       "14     15       W              W\n",
       "15     16       W              W"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.622636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.622636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.903830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.903830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.903830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.460520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.460520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.460520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.460520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.403328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.403328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.403328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.403328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.403328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     compass\n",
       "0   0.622636\n",
       "1   0.622636\n",
       "2   0.903830\n",
       "3   0.903830\n",
       "4   0.903830\n",
       "5   0.176600\n",
       "6   0.176600\n",
       "7   0.460520\n",
       "8   0.460520\n",
       "9   0.460520\n",
       "10  0.460520\n",
       "11  0.403328\n",
       "12  0.403328\n",
       "13  0.403328\n",
       "14  0.403328\n",
       "15  0.403328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from category_encoders.datasets import load_compass\n",
    "X, y = load_compass()\n",
    "display(X)\n",
    "hierarchical_map = {'compass': {'N': ('N', 'NE'), 'S': ('S', 'SE'), 'W': 'W'}}\n",
    "enc = TargetEncoder(verbose=1, smoothing=2, min_samples_leaf=2, hierarchy=hierarchical_map, cols=['compass']).fit(X.loc[:,['compass']], y)\n",
    "hierarchy_dataset = enc.transform(X.loc[:,['compass']])\n",
    "display(hierarchy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import warnings\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "class PLOrdinalEncoder:\n",
    "    \"\"\"Encodes categorical features as ordinal, in one ordered feature.\n",
    "\n",
    "    Ordinal encoding uses a single column of integers to represent the classes. An optional mapping dict can be passed\n",
    "    in; in this case, we use the knowledge that there is some true order to the classes themselves. Otherwise, the classes\n",
    "    are assumed to have no true order and integers are selected at random.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose: int\n",
    "        integer indicating verbosity of the output. 0 for none.\n",
    "    cols: list\n",
    "        a list of columns to encode, if None, all string columns will be encoded.\n",
    "    drop_invariant: bool\n",
    "        boolean for whether or not to drop columns with 0 variance.\n",
    "    return_df: bool\n",
    "        boolean for whether to return a Polars DataFrame from transform (otherwise it will be a numpy array).\n",
    "    mapping: list of dicts\n",
    "        a mapping of class to label to use for the encoding, optional.\n",
    "        the dict contains the keys 'col' and 'mapping'.\n",
    "        the value of 'col' should be the feature name.\n",
    "        the value of 'mapping' should be a dictionary or pl.Series of 'original_label' to 'encoded_label'.\n",
    "    handle_unknown: str\n",
    "        options are 'error', 'return_nan' and 'value', defaults to 'value', which will impute the category -1.\n",
    "    handle_missing: str\n",
    "        options are 'error', 'return_nan', and 'value, default to 'value', which treat nan as a category at fit time,\n",
    "        or -2 at transform time if nan is not a category during fit.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0, mapping=None, cols=None, drop_invariant=False, return_df=True,\n",
    "                 handle_unknown='value', handle_missing='value'):\n",
    "        self.verbose = verbose\n",
    "        self.mapping_supplied = mapping is not None\n",
    "        if self.mapping_supplied:\n",
    "            self.mapping = self._validate_supplied_mapping(mapping)\n",
    "        else:\n",
    "            self.mapping = None\n",
    "        self.cols = cols\n",
    "        self.drop_invariant = drop_invariant\n",
    "        self.return_df = return_df\n",
    "        self.handle_unknown = handle_unknown\n",
    "        self.handle_missing = handle_missing\n",
    "\n",
    "    @property\n",
    "    def category_mapping(self):\n",
    "        return self.mapping\n",
    "\n",
    "    def _fit(self, X, y=None, **kwargs):\n",
    "        try:\n",
    "            _, categories = self.ordinal_encoding(\n",
    "                X,\n",
    "                mapping=self.mapping,\n",
    "                cols=self.cols,\n",
    "                handle_unknown=self.handle_unknown,\n",
    "                handle_missing=self.handle_missing\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\"Columns in DataFrame:\", X.columns)\n",
    "            raise\n",
    "        \"\"\"\n",
    "        display(self.cols)\n",
    "        if not self.mapping_supplied:\n",
    "            self.mapping = None\n",
    "        _, categories = self.ordinal_encoding(\n",
    "            X,\n",
    "            mapping=self.mapping,\n",
    "            cols=self.cols,\n",
    "            handle_unknown=self.handle_unknown,\n",
    "            handle_missing=self.handle_missing\n",
    "        )\n",
    "        self.mapping = categories\n",
    "        \"\"\"\n",
    "    def _transform(self, X):\n",
    "        X, _ = self.ordinal_encoding(\n",
    "            X,\n",
    "            mapping=self.mapping,\n",
    "            cols=self.cols,\n",
    "            handle_unknown=self.handle_unknown,\n",
    "            handle_missing=self.handle_missing\n",
    "        )\n",
    "        return X\n",
    "\n",
    "    def inverse_transform(self, X: pl.DataFrame):\n",
    "        if self._dim is None:\n",
    "            raise ValueError('Must train encoder before it can be used to inverse_transform data')\n",
    "\n",
    "        if X.shape[1] != self._dim:\n",
    "            raise ValueError(f'Unexpected input dimension {X.shape[1]}, expected {self._dim}')\n",
    "\n",
    "        if not self.cols:\n",
    "            return X if self.return_df else X.to_numpy()\n",
    "\n",
    "        for switch in self.mapping:\n",
    "            column_mapping = switch.get('mapping')\n",
    "            inverse = {v: k for k, v in column_mapping.items()}\n",
    "            X = X.with_columns(pl.col(switch.get('col')).apply(lambda x: inverse.get(x, x)))\n",
    "\n",
    "        return X if self.return_df else X.to_numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def ordinal_encoding(X_in: pl.DataFrame, mapping=None, cols=None, handle_unknown='value', handle_missing='value'):\n",
    "        if cols is None:\n",
    "            cols = X_in.columns\n",
    "        else:\n",
    "            # 確認している列がDataFrameに存在するかどうかをチェック\n",
    "            missing_cols = [col for col in cols if col not in X_in.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Columns not found in DataFrame: {missing_cols}\")\n",
    "            \n",
    "        if mapping is not None:\n",
    "            mapping_out = mapping\n",
    "            for switch in mapping:\n",
    "                column = switch.get('col')\n",
    "                col_mapping = switch['mapping']\n",
    "                X_in = X_in.with_columns(\n",
    "                    pl.when(X_in[column].is_in(list(col_mapping.keys())))\n",
    "                    .then(pl.element().map_batches(col_mapping))\n",
    "                    .otherwise(-1 if handle_unknown == 'value' else pl.element())\n",
    "                    .alias(column)\n",
    "                )\n",
    "                if handle_missing == 'return_nan':\n",
    "                    X_in = X_in.with_columns(\n",
    "                        pl.when(X_in[column].is_null())\n",
    "                        .then(-2)\n",
    "                        .otherwise(X_in[column])\n",
    "                        .alias(column)\n",
    "                    )\n",
    "        else:\n",
    "            mapping_out = []\n",
    "            for col in cols:\n",
    "                categories = X_in[col].unique().to_numpy()\n",
    "                index = {val: idx + 1 for idx, val in enumerate(categories) if val is not None}\n",
    "\n",
    "                if handle_missing == 'value':\n",
    "                    index[None] = -2  # Use None for missing values in polars\n",
    "\n",
    "                mapping_out.append({'col': col, 'mapping': index, 'data_type': X_in[col].dtype})\n",
    "\n",
    "                X_in = X_in.with_columns(\n",
    "                    pl.when(X_in[col].is_in(list(index.keys())))\n",
    "                    .then(pl.element().map_batches(index))\n",
    "                    .otherwise(-1 if handle_unknown == 'value' else pl.element())\n",
    "                    .alias(col)\n",
    "                )\n",
    "\n",
    "        return X_in, mapping_out\n",
    "\n",
    "\n",
    "    def _validate_supplied_mapping(self, supplied_mapping: List[Dict[str, Union[str, Dict, pl.Series]]]) -> List[Dict[str, Union[str, pl.Series]]]:\n",
    "        if not isinstance(supplied_mapping, list):\n",
    "            raise ValueError(\"Invalid supplied mapping, must be of type List[Dict[str, Union[Dict, pl.Series]]].\")\n",
    "        for mapping_el in supplied_mapping:\n",
    "            if not isinstance(mapping_el, dict):\n",
    "                raise ValueError(\"Invalid supplied mapping, must be of type List[Dict[str, Union[Dict, pl.Series]]].\")\n",
    "            if \"col\" not in mapping_el:\n",
    "                raise KeyError(\"Mapping must contain a key 'col' for each column to encode\")\n",
    "            if \"mapping\" not in mapping_el:\n",
    "                raise KeyError(\"Mapping must contain a key 'mapping' for each column to encode\")\n",
    "            mapping = mapping_el[\"mapping\"]\n",
    "            if isinstance(mapping, dict):\n",
    "                mapping_el[\"mapping\"] = pl.Series(list(mapping.keys()), values=list(mapping.values()), dtype=pl.Categorical)\n",
    "            if \"data_type\" not in mapping_el:\n",
    "                mapping_el[\"data_type\"] = mapping_el[\"mapping\"].dtype\n",
    "        return supplied_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import *\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "bunch = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "display_cols = [\"Id\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"YearBuilt\", \"Heating\", \"CentralAir\"]\n",
    "y = bunch.target\n",
    "X = pl.DataFrame(bunch.data)[display_cols]\n",
    "display(X)\n",
    "encoder = PLOrdinalEncoder(cols=['CentralAir', 'Heating'])._fit(X, y)\n",
    "numeric_dataset = enc.transform(X)\n",
    "#print(numeric_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_460, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Id</th><th>MSSubClass</th><th>MSZoning</th><th>LotFrontage</th><th>YearBuilt</th><th>Heating</th><th>CentralAir</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>60</td><td>&quot;RL&quot;</td><td>65.0</td><td>2003</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr><tr><td>2</td><td>20</td><td>&quot;RL&quot;</td><td>80.0</td><td>1976</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr><tr><td>3</td><td>60</td><td>&quot;RL&quot;</td><td>68.0</td><td>2001</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr><tr><td>4</td><td>70</td><td>&quot;RL&quot;</td><td>60.0</td><td>1915</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr><tr><td>5</td><td>60</td><td>&quot;RL&quot;</td><td>84.0</td><td>2000</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1456</td><td>60</td><td>&quot;RL&quot;</td><td>62.0</td><td>1999</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr><tr><td>1457</td><td>20</td><td>&quot;RL&quot;</td><td>85.0</td><td>1978</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr><tr><td>1458</td><td>70</td><td>&quot;RL&quot;</td><td>66.0</td><td>1941</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr><tr><td>1459</td><td>20</td><td>&quot;RL&quot;</td><td>68.0</td><td>1950</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr><tr><td>1460</td><td>20</td><td>&quot;RL&quot;</td><td>75.0</td><td>1965</td><td>&quot;GasA&quot;</td><td>&quot;Y&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_460, 7)\n",
       "┌──────┬────────────┬──────────┬─────────────┬───────────┬─────────┬────────────┐\n",
       "│ Id   ┆ MSSubClass ┆ MSZoning ┆ LotFrontage ┆ YearBuilt ┆ Heating ┆ CentralAir │\n",
       "│ ---  ┆ ---        ┆ ---      ┆ ---         ┆ ---       ┆ ---     ┆ ---        │\n",
       "│ i64  ┆ i64        ┆ str      ┆ f64         ┆ i64       ┆ str     ┆ str        │\n",
       "╞══════╪════════════╪══════════╪═════════════╪═══════════╪═════════╪════════════╡\n",
       "│ 1    ┆ 60         ┆ RL       ┆ 65.0        ┆ 2003      ┆ GasA    ┆ Y          │\n",
       "│ 2    ┆ 20         ┆ RL       ┆ 80.0        ┆ 1976      ┆ GasA    ┆ Y          │\n",
       "│ 3    ┆ 60         ┆ RL       ┆ 68.0        ┆ 2001      ┆ GasA    ┆ Y          │\n",
       "│ 4    ┆ 70         ┆ RL       ┆ 60.0        ┆ 1915      ┆ GasA    ┆ Y          │\n",
       "│ 5    ┆ 60         ┆ RL       ┆ 84.0        ┆ 2000      ┆ GasA    ┆ Y          │\n",
       "│ …    ┆ …          ┆ …        ┆ …           ┆ …         ┆ …       ┆ …          │\n",
       "│ 1456 ┆ 60         ┆ RL       ┆ 62.0        ┆ 1999      ┆ GasA    ┆ Y          │\n",
       "│ 1457 ┆ 20         ┆ RL       ┆ 85.0        ┆ 1978      ┆ GasA    ┆ Y          │\n",
       "│ 1458 ┆ 70         ┆ RL       ┆ 66.0        ┆ 1941      ┆ GasA    ┆ Y          │\n",
       "│ 1459 ┆ 20         ┆ RL       ┆ 68.0        ┆ 1950      ┆ GasA    ┆ Y          │\n",
       "│ 1460 ┆ 20         ┆ RL       ┆ 75.0        ┆ 1965      ┆ GasA    ┆ Y          │\n",
       "└──────┴────────────┴──────────┴─────────────┴───────────┴─────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n",
      "Columns in DataFrame: ['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'YearBuilt', 'Heating', 'CentralAir']\n"
     ]
    },
    {
     "ename": "ColumnNotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mDataFrame(bunch\u001b[38;5;241m.\u001b[39mdata)[display_cols]\n\u001b[1;32m      3\u001b[0m display(X)\n\u001b[0;32m----> 4\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mPLOrdinalEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCentralAir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHeating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m numeric_dataset \u001b[38;5;241m=\u001b[39m enc\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#print(numeric_dataset.info())\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 54\u001b[0m, in \u001b[0;36mPLOrdinalEncoder._fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m         _, categories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mordinal_encoding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_missing\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 144\u001b[0m, in \u001b[0;36mPLOrdinalEncoder.ordinal_encoding\u001b[0;34m(X_in, mapping, cols, handle_unknown, handle_missing)\u001b[0m\n\u001b[1;32m    140\u001b[0m             index[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Use None for missing values in polars\u001b[39;00m\n\u001b[1;32m    142\u001b[0m         mapping_out\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m'\u001b[39m: col, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmapping\u001b[39m\u001b[38;5;124m'\u001b[39m: index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m'\u001b[39m: X_in[col]\u001b[38;5;241m.\u001b[39mdtype})\n\u001b[0;32m--> 144\u001b[0m         X_in \u001b[38;5;241m=\u001b[39m \u001b[43mX_in\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_in\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_in\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43motherwise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_in, mapping_out\n",
      "File \u001b[0;32m~/VScode/ML_Utilities/.venv/lib/python3.9/site-packages/polars/dataframe/frame.py:8634\u001b[0m, in \u001b[0;36mDataFrame.with_columns\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   8488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_columns\u001b[39m(\n\u001b[1;32m   8489\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8490\u001b[0m     \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr],\n\u001b[1;32m   8491\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr,\n\u001b[1;32m   8492\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   8493\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   8494\u001b[0m \u001b[38;5;124;03m    Add columns to this DataFrame.\u001b[39;00m\n\u001b[1;32m   8495\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8632\u001b[0m \u001b[38;5;124;03m    └─────┴──────┴─────────────┘\u001b[39;00m\n\u001b[1;32m   8633\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 8634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VScode/ML_Utilities/.venv/lib/python3.9/site-packages/polars/lazyframe/frame.py:1967\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, no_optimization, streaming, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;66;03m# Only for testing purposes atm.\u001b[39;00m\n\u001b[1;32m   1965\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def ordinal_encoding(X_in: pl.DataFrame, mapping=None, cols=None, handle_unknown='value', handle_missing='value'):\n",
    "        if cols is None:\n",
    "            cols = X_in.columns\n",
    "        else:\n",
    "            # 確認している列がDataFrameに存在するかどうかをチェック\n",
    "            missing_cols = [col for col in cols if col not in X_in.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Columns not found in DataFrame: {missing_cols}\")\n",
    "            \n",
    "        if mapping is not None:\n",
    "            mapping_out = mapping\n",
    "            for switch in mapping:\n",
    "                column = switch.get('col')\n",
    "                col_mapping = switch['mapping']\n",
    "                X_in = X_in.with_columns(\n",
    "                    pl.when(X_in[column].is_in(list(col_mapping.keys())))\n",
    "                    .then(pl.element().map_batches(col_mapping))\n",
    "                    .otherwise(-1 if handle_unknown == 'value' else pl.element())\n",
    "                    .alias(column)\n",
    "                )\n",
    "                if handle_missing == 'return_nan':\n",
    "                    X_in = X_in.with_columns(\n",
    "                        pl.when(X_in[column].is_null())\n",
    "                        .then(-2)\n",
    "                        .otherwise(X_in[column])\n",
    "                        .alias(column)\n",
    "                    )\n",
    "        else:\n",
    "            mapping_out = []\n",
    "            for col in cols:\n",
    "                categories = X_in[col].unique().to_numpy()\n",
    "                index = {val: idx + 1 for idx, val in enumerate(categories) if val is not None}\n",
    "\n",
    "                if handle_missing == 'value':\n",
    "                    index[None] = -2  # Use None for missing values in polars\n",
    "\n",
    "                mapping_out.append({'col': col, 'mapping': index, 'data_type': X_in[col].dtype})\n",
    "\n",
    "                X_in = X_in.with_columns(\n",
    "                    pl.when(X_in[col].is_in(list(index.keys())))\n",
    "                    .then(pl.element().map_batches(index))\n",
    "                    .otherwise(-1 if handle_unknown == 'value' else pl.element())\n",
    "                    .alias(col)\n",
    "                )\n",
    "\n",
    "        return X_in, mapping_out\n",
    "    \n",
    "def fit(X_in: pl.DataFrame, mapping=None, cols=None, handle_unknown='value', handle_missing='value'):\n",
    "    try:\n",
    "        _, categories = ordinal_encoding(\n",
    "            X,\n",
    "            mapping=mapping,\n",
    "            cols=cols,\n",
    "            handle_unknown=handle_unknown,\n",
    "            handle_missing=handle_missing\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Columns in DataFrame:\", X.columns)\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
